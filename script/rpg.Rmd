---
title: "RPG"
author: "B. Maranget"
date: "08/01/2021"
output: 
  html_document: 
    number_sections: yes
    toc: yes
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache = TRUE)
# Passer la valeur suivante à TRUE pour reproduire les extractions.
knitr::opts_chunk$set(eval = TRUE)
knitr::opts_chunk$set(warning = FALSE)
```

# Cadre

## Objet

Récupérer le segment d'appartenance pour chaque commune.

## Librairies et répertoire

```{r}
library(sf)
library(cartography)
library(rgdal)
```

# Données

```{r}
# communes sans la corse
commune <- st_read("../dataE/00_ADMIN/ign.gpkg", "commune", quiet = TRUE,stringsAsFactors = F)
dpt <- st_read("../dataE/00_ADMIN/ign.gpkg", "dpt", quiet = TRUE, stringsAsFactors = F)
ogrListLayers("../dataE/01_CULTURES/PARCELLES_GRAPHIQUES.gpkg") 
ogrListLayers("../dataE/01_CULTURES/ILOTS_ANONYMES.gpkg") 
rpg <-  st_read("../dataE/01_CULTURES/PARCELLES_GRAPHIQUES.gpkg", "parcelle_graphique", quiet = TRUE, stringsAsFactors = F)
ilots <-  st_read("../dataE/01_CULTURES/ILOTS_ANONYMES.gpkg", "ilots_anonymes", quiet = TRUE, stringsAsFactors = F)
```


# Explorations (Ne pas jouer)

## Communes et cantons 2020 : exploration, combien de communes fractionnées

Plus de communes officiellement fractionnées que par calcul, aie !

```{r}
# 2054 cantons en 2020 (communes nouvelles et multicantons 286)
table(can2020$typect)
# 434 communes fractionnées (les plus grosses)
# Dans le code officiel géographique, les communes multicantonnales sont codées > 79
tab <- table(com2020$can)
# 3033 communes sans code canton ?
sapply(com2020$can,nchar)
# lg vides, les communes assoicées ou déléguées n'ont pas de canton ? 3033 cas
tab [1]
df <- as.data.frame(tab [-1])
# on supprime ces 3033 cas.
df$chiffre <- as.integer(substr(df$Var1,3,4) )
df1 <- df [df$chiffre > 79,]
sum(df1$Freq) 
# 282 communes fractionnées d'après mon calcul...
```

## Segments, quelle version de fichier ? V11 ou segment ?

Peu importe. On prend la segment au final. 
Hypothèse : La version finale doit comporter les entêtes pour la mise à jour sur le site ?

```{r}
# plusieurs couches segments

str(segment)
str(segmentV11)
# pas les mêmes variables V11 moins protocolaire
egal <- st_equals(segment, segmentV11, sparse = TRUE)
# on teste la présence d'une géométrie non identique
table (sapply(egal, length))
# les 192 géométries sont identiques !
```


## Segments et cantons


Moins de 500 communes sont découpées dans les cantons et les segments sont basés sur des cantons...
Simplement il y a 192 segments. Observons déjà segment et cantons
Pour la géométrie des cantons, elle n'existe pas dans admin express, on la prend dans geofla 2015

Donc la piste canton - segment n'est pas bonne. Le travail se fait sur commune - segment.

```{r}
canton <- st_read("../dataE/00_ADMIN/CANTON.SHP")
# 2378 cantons en 2015
S_cantonSegment <- st_within(canton, segment, sparse = T)
table (sapply(S_cantonSegment, length))
# 2065 cantons ne sont pas dans les segments ...
```

## Vérification de la méthode, commune et dpt

Au passage on regarde les deux formes matrice simplifiée et matrice logique

Toutes les communes sont dans un département ! Ouf !

```{r}
S_communeDpt <-  st_within(commune, dpt, sparse = T)
M_communeDpt <-  st_within(commune, dpt, sparse = F)

S_communeDpt
M_communeDpt

str(S_communeDpt)

table(sapply(S_communeDpt,length))
# Toutes les communes sont dans un dpt
```

# Cas d'étude : segments et communes

Les segments ne représentent pas une couverture exhaustive de l'espace. 
Du coup, on exclue toutes les communes sur ces segments.
Une méthode simple est de partir des centroides, d'intersecter et de repartir de la base
commune obtenue.

```{r}
centroid <- st_centroid(commune)
data <- st_intersection(centroid, segment)
# verif graphique sur les communes exclues
diff <- setdiff(centroid$INSEE_COM, data$INSEE_COM)
dataDiff <- commune [commune$INSEE_COM %in% diff,]
plot(dataDiff$geom)
# constitution base commune : polygone et champs INSEE_COM et NOM_COM uniquement
commune <- commune [!(commune$INSEE_COM %in% diff), c("INSEE_COM", "NOM_COM")]
# 31 565 communes inclues dans les segments, 3000 exclues

```

On détecte les communes dans un segment
ou / et ?
On intersecte et on mesure les aires des communes hors segment

## Within

```{r}
communeSegment <- st_within(commune, segment, sparse = T)
communeSegment
unlist(communeSegment)
# attention il s'agit des indices pour commune comme pour segment
# recup des communes - segments
res <- sapply(communeSegment, length)
table(res)
# recup indice communes inclues 18190
indiceCom <-  which (res != 0)
# recup communes et segments via les indices
com <- commune[indiceCom,]
seg <- segment [unlist(communeSegment),]
# attribution du segment par jointure attributaire
tmpCom <- cbind (com, seg )
tmpSeg <-  seg [, c("Codgeo_NUM", "libgeo"), drop = TRUE] 
tmpSeg <- unique(tmpSeg)
# une commune par segment donc 18190 obs
comSeg1 <- merge (tmpCom [, c("INSEE_COM", "NOM_COM","Codgeo_NUM")], tmpSeg, by = "Codgeo_NUM")
# 18190 communes dans segments
# filtre sur les communes problématiques, celles qui sont vides dans la liste
indiceComPb <- which(res == 0)
comPb <- commune [indiceComPb,]
```



16 678 communes ne sont pas dans un segment, quasiment la moitié.
On intersecte ensuite

## La base de travail : comSegment

```{r}
comSegment <- st_intersection(comPb, segment)
str(comSegment)
comSegment <- comSegment [, c("NOM_COM", "INSEE_COM", "codgeo", "libgeo")]
```

27 220 morceaux pour 16 678 communes. donc 10 M de trop.

## Exploration cas Aast et 4 segments

### Un exemple de problème topologique : Aast

```{r}
Aast <- comSegment [comSegment$NOM_COM == "Aast",]
Aast
plot(Aast$geom)
par(mfrow = c(1,3))
for (i in 1:3) { plot (Aast$geom [i])}
# une piste : taille des intersections ?
taille <- sapply(Aast$geom, st_area)
taille100 <- (taille / sum(taille)) *100

```

### Compter le nombre de parties de communes

```{r}
tab <- table(comSegment$"INSEE_COM")
table(tab)
max(tab)
# représentation graphique
barplot(sort(tab), las = 2, main = paste0(length(tab), " communes représentées entre 1 et 5 fois"))
```

Méthode : 

- on extrait la fréquence, 
* on représente barplot,
- et on filtre la base des communes sélectionnées

point de vigilance : attention à travailler avec le code unique commune ! (code INSEE)

```{r}
# nb choix de la limite
nb <- 1
code <- names(tab) [tab > nb]
par(mar = c(8,4,4,4))
tab <- tab [tab > nb] 
barplot(sort(tab), las = 2, main = paste0(length(tab), " communes représentées plus de ", nb,"  fois"))
comSeg <- comSegment [comSegment$INSEE_COM %in% code,]
# nb de morceaux
```

Vérification à partir base commune sans le within

```{r}
# rappel code = communes plus de 2 fois
sel <- commune [commune$INSEE_COM %in% code,]
inter <- st_intersection(sel, segment)
# 11842 communes et 24837  morceaux également ! pas besoin de passer par le within (strictement à l'intérieur)
```

## Calcul des aires pour éliminer les problèmes d'ordre topologiques

On repart de la base commune (sel et inter)

```{r}
# aire des communes et de leurs parties
sel$aire <- sapply(sel$geom, st_area)
inter$aire <- sapply(inter$geom, st_area)
inter <- inter [, c("INSEE_COM", "NOM_COM", "codgeo", "libgeo","aire")]
str(inter)
# il s'agit d'obtenir les rapports entre les aires par ville
pct <- function (vecteur) {(vecteur / sum(vecteur)) * 100}
# Pour pouvoir traiter chaque ville, on éclate en liste
linter <- split(inter, inter$INSEE_COM)
names(linter)
linter [[1]]
nb <- length(linter)
# l'aire est sur chaque 5e col de chacune des 46 listes
# On extrait pour toutes les listes uniquement la 5e colonne
laire <- list()
for (i in 1:nb) { 
  laire [[i]] <- linter [[i]][,5, drop = TRUE]
  names (laire) [[i]] <- linter [[i]][1,1, drop = TRUE] 
}
# on repère les communes dont les parties sont minimes par rapport au total des aires

# on cherche l'aire max
laire.pct <- lapply (laire, pct)
# on voit qu'il existe tjrs une aire principale occupant + de 90 % de la surface.
laire.pct.max <- lapply(laire.pct, max)
comOK <- laire.pct.max [laire.pct.max >= 90]
anomalies <- laire.pct.max [laire.pct.max <90]
# 128 anomalies
nom.anomalies <- names(anomalies)
plot(commune$geom [commune$INSEE_COM %in% nom.anomalies,])
# cartographies
nb <- length(nom.anomalies)
i <- 1
for (i in 1:nb) {
  g <- inter$geom [inter$INSEE_COM == nom.anomalies [i]]
  sizes <-
    getFigDim(
      x = g,
      width = 300,
      mar = c(0, 0, 1.2, 0),
      res = 96
    )
  png(
    paste0("../img/anomalies_", i, ".png"),
    width = 300,
    height = sizes [2],
    res = 96
  )
  par(mar = c(0, 0, 1.2, 0))
  plot(g, bg = "antiquewhite1")
  segSel <-
    st_intersection(segment, g)
  noms <- unique(segSel$libgeo)
  segmentSel <- segment [segment$libgeo %in% noms,]
  typoLayer(segmentSel, var = "libgeo", add = TRUE)
  plot(
    inter$geom [inter$INSEE_COM == nom.anomalies [i]],
    lwd = 2,
    border = "red",
    add = TRUE,
    col = NA
  )
  layoutLayer(paste0("Commune de ", inter$NOM_COM [inter$INSEE_COM == nom.anomalies [i]],  " et segments"))
  dev.off()
}

```

## Table finale

Idée : sauf pour les 128 anomalies, reprendre les centroides

C'est quand même beaucoup plus simple.

```{r}
nom.anomalies
centr <- st_centroid(commune)
res <- st_intersection(centr, segment)
# 31565 communes sur 34868.pourquoi une différence de 3 303 ? Il s'agit sans doute des centroids sur espace sans segment.
# Mais il devrait y en avoir moins (71, cf calculs ci-dessous)
# on supprime les anomales
head(res)
res <- res [!(res$INSEE_COM %in% nom.anomalies), ]
res <- res [, c("INSEE_COM", "NOM_COM", "codgeo", "libgeo"), drop= TRUE]
# 31494 communes sur 34868, seules 71 communes ont été retirées...
# reste 57 cas problématiques.
nb <- 31565 - nrow(res)
length(nom.anomalies)- nb
# merge géométries commune
res2 <- merge (res, commune [, "INSEE_COM"], by = "INSEE_COM")
head(res2)
```

reste les 128 communes... analyse des cartographies

cas des communes sur aucun segment, là aussi repérage par rapport au centroid et exclusion
de ces communes.

Il faut également vérifier qu'il reste 57 cas

De plus, on comprendra peut-ètre pourquoi différence de 3303

```{r}
# variables : nom.anomalies
head(centr)
centrAnomalies <- centr [centr$INSEE_COM %in% nom.anomalies,]
resAnomalies <- st_intersection(centrAnomalies, segment)
# remplacement du point par le polygone
resAnomaliesPoly <- resAnomalies [, c("INSEE_COM", "NOM_COM", "codgeo", "libgeo"),drop = TRUE]
resAnomaliesPoly <- merge (resAnomaliesPoly, commune [, "INSEE_COM"], by = "INSEE_COM")
# 71 communes communes ont un centroid dans un segment.
# Les 57 autres cas sont à retirer.
commHorsSegment <- setdiff(centrAnomalies$INSEE_COM, resAnomalies$INSEE_COM)
# cartographies des 71 cas.
nb <- nrow(resAnomaliesPoly)
i <- 1
for (i in 1:nb) {
  g <- resAnomaliesPoly$geom [i]
  sizes <-
    getFigDim(
      x = g,
      width = 300,
      mar = c(0, 0, 1.2, 0),
      res = 96
    )
  png(
    paste0("../img/anomaliesTri_", i, ".png"),
    width = 300,
    height = sizes [2],
    res = 96
  )
  par(mar = c(0, 0, 1.2, 0))
  plot(g, bg = "antiquewhite1")
  segSel <-
    st_intersection(segment, g)
  noms <- unique(segSel$libgeo)
  segmentSel <- segment [segment$libgeo %in% noms,]
  typoLayer(segmentSel, var = "libgeo", add = TRUE)
  plot(
    g,
    lwd = 2,
    border = "red",
    add = TRUE,
    col = NA
  )
  layoutLayer(paste0("Commune de ", resAnomaliesPoly$NOM_COM [i],  " et segments"))
  dev.off()
}
```

Analyse des 71 cas

Il reste beaucoup de cas où les aires débordent sans signification !
Trouver la bonne borne au dessus de 90 %

```{r}
anomalies <- laire.pct.max [laire.pct.max < 70]
nom.anomalies <- names(anomalies)
# 42
```

