---
title: "Segment"
author: "B. Maranget"
date: "08/12/2020"
output: 
  html_document: 
    number_sections: yes
    toc: yes
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache = TRUE)
# Passer la valeur suivante à TRUE pour reproduire les extractions.
knitr::opts_chunk$set(eval = TRUE)
knitr::opts_chunk$set(warning = FALSE)
```

# Cadre

## Objet

Récupérer le segment d'appartenance pour chaque commune.

## Librairies et répertoire

```{r}
library(sf)
library(cartography)
```

# Données

```{r}
# communes sans la corse
commune <- st_read("../dataE/00_ADMIN/ign.gpkg", "commune", quiet = TRUE,stringsAsFactors = F)
dpt <- st_read("../dataE/00_ADMIN/ign.gpkg", "dpt", quiet = TRUE, stringsAsFactors = F)
# liste commune canton
com2020 <- read.csv("../dataE/00_ADMIN/communes2020.csv")
can2020 <- read.csv("../dataE/00_ADMIN/canton2020.csv")
# 2 fichiers de segments
segmentV11 <-  st_read("../dataS/segment.gpkg", "v11", stringsAsFactors = F)
segment <- st_read("../dataE/01_CULTURES/segments_syst_L93.shp",  stringsAsFactors = F)
```


# Explorations (Ne pas jouer)

## Communes et cantons 2020 : exploration, combien de communes fractionnées

Plus de communes officiellement fractionnées que par calcul, aie !

```{r}
# 2054 cantons en 2020 (communes nouvelles et multicantons 286)
table(can2020$typect)
# 434 communes fractionnées (les plus grosses)
# Dans le code officiel géographique, les communes multicantonnales sont codées > 79
tab <- table(com2020$can)
# 3033 communes sans code canton ?
sapply(com2020$can,nchar)
# lg vides, les communes assoicées ou déléguées n'ont pas de canton ? 3033 cas
tab [1]
df <- as.data.frame(tab [-1])
# on supprime ces 3033 cas.
df$chiffre <- as.integer(substr(df$Var1,3,4) )
df1 <- df [df$chiffre > 79,]
sum(df1$Freq) 
# 282 communes fractionnées d'après mon calcul...
```

## Segments, quelle version de fichier ? V11 ou segment ?

Peu importe. On prend la segment au final. 
Hypothèse : La version finale doit comporter les entêtes pour la mise à jour sur le site ?

```{r}
# plusieurs couches segments

str(segment)
str(segmentV11)
# pas les mêmes variables V11 moins protocolaire
egal <- st_equals(segment, segmentV11, sparse = TRUE)
# on teste la présence d'une géométrie non identique
table (sapply(egal, length))
# les 192 géométries sont identiques !
```


## Segments et cantons


Moins de 500 communes sont découpées dans les cantons et les segments sont basés sur des cantons...
Simplement il y a 192 segments. Observons déjà segment et cantons
Pour la géométrie des cantons, elle n'existe pas dans admin express, on la prend dans geofla 2015

Donc la piste canton - segment n'est pas bonne. Le travail se fait sur commune - segment.

```{r}
canton <- st_read("../dataE/00_ADMIN/CANTON.SHP")
# 2378 cantons en 2015
S_cantonSegment <- st_within(canton, segment, sparse = T)
table (sapply(S_cantonSegment, length))
# 2065 cantons ne sont pas dans les segments ...
```

## Vérification de la méthode, commune et dpt

Au passage on regarde les deux formes matrice simplifiée et matrice logique

Toutes les communes sont dans un département ! Ouf !

```{r}
S_communeDpt <-  st_within(commune, dpt, sparse = T)
M_communeDpt <-  st_within(commune, dpt, sparse = F)

S_communeDpt
M_communeDpt

str(S_communeDpt)

table(sapply(S_communeDpt,length))
# Toutes les communes sont dans un dpt
```

# Cas d'étude : segments et communes

Les segments ne représentent pas une couverture exhaustive de l'espace. 
Du coup, on exclue toutes les communes sur ces segments.
Une méthode simple est de partir des centroides, d'intersecter et de repartir de la base
commune obtenue.

```{r}
centroid <- st_centroid(commune)
data <- st_intersection(centroid, segment)
# verif graphique sur les communes exclues
diff <- setdiff(centroid$INSEE_COM, data$INSEE_COM)
dataDiff <- commune [commune$INSEE_COM %in% diff,]
plot(dataDiff$geom)
# on rajoutera le dataDiff à la table principale avec la mention 00 et "hors segment"
st_write(dataDiff, "../dataS/segment.gpkg", "communeHorsSegment", quiet = TRUE, delete_layer = TRUE  )
# affichage sous Qgis permet de repérer pb estuaire de la gironde.
# certaines communes isolées au mileu d'un segment... nécessité expertise...
# constitution base commune : polygone et champs INSEE_COM et NOM_COM uniquement
commune <- commune [!(commune$INSEE_COM %in% diff), c("INSEE_COM", "NOM_COM")]
# 31 565 communes inclues dans les segments, 3000 exclues

```

On détecte les communes dans un segment
ou / et ?
On intersecte et on mesure les aires des communes hors segment

## Within

```{r}
communeSegment <- st_within(commune, segment, sparse = T)
communeSegment
unlist(communeSegment)
# attention il s'agit des indices pour commune comme pour segment
# recup des communes - segments
res <- sapply(communeSegment, length)
table(res)
# recup indice communes inclues 18190
indiceCom <-  which (res != 0)
# recup communes et segments via les indices
com <- commune[indiceCom,]
seg <- segment [unlist(communeSegment),]
# attribution du segment par jointure attributaire
tmpCom <- cbind (com, seg )
tmpSeg <-  seg [, c("Codgeo_NUM", "libgeo"), drop = TRUE] 
tmpSeg <- unique(tmpSeg)
# une commune par segment donc 18190 obs
comSegOK <- merge (tmpCom [, c("INSEE_COM", "NOM_COM","Codgeo_NUM")], tmpSeg, by = "Codgeo_NUM")
# 18190 communes dans segments
# filtre sur les communes problématiques, celles qui sont vides dans la liste
indiceComPb <- which(res == 0)
comPb <- commune [indiceComPb,]
```


13 375 communes ne sont pas dans un segment, quasiment la moitié.
On intersecte ensuite

## La base de travail : comSegment

```{r}
comSegment <- st_intersection(comPb, segment)
str(comSegment)
comSegment <- comSegment [, c("NOM_COM", "INSEE_COM", "codgeo", "libgeo")]
```

26 276 morceaux pour 13 375 communes. toutes les communes en 2 morceaux ?

## Exploration cas Aast et 4 segments

### Un exemple de problème topologique : Aast

```{r}
Aast <- comSegment [comSegment$NOM_COM == "Aast",]
Aast
plot(Aast$geom)
par(mfrow = c(1,3))
for (i in 1:3) { plot (Aast$geom [i])}
# une piste : taille des intersections ?
taille <- sapply(Aast$geom, st_area)
taille100 <- (taille / sum(taille)) *100

```

### Compter le nombre de parties de communes

```{r}
tab <- table(comSegment$"INSEE_COM")
table(tab)
max(tab)
# représentation graphique
barplot(sort(tab), las = 2, main = paste0(length(tab), " communes représentées entre 1 et 5 fois"))
```

Méthode : 

- on extrait la fréquence, 
* on représente barplot,
- et on filtre la base des communes sélectionnées

point de vigilance : attention à travailler avec le code unique commune ! (code INSEE)

```{r}
# nb choix de la limite
nb <- 1
code <- names(tab) [tab > nb]
par(mar = c(8,4,4,4))
tab <- tab [tab > nb] 
barplot(sort(tab), las = 2, main = paste0(length(tab), " communes représentées plus de ", nb,"  fois"))
comSeg <- comSegment [comSegment$INSEE_COM %in% code,]
# nb de morceaux 24 656
```

Vérification à partir base commune sans le within

```{r}
# rappel code = communes plus de 2 fois
sel <- commune [commune$INSEE_COM %in% code,]
inter <- st_intersection(sel, segment)
# 11755 communes et 24656  morceaux également ! pas besoin de passer par le within (strictement à l'intérieur)
```

## Calcul des aires pour éliminer les problèmes d'ordre topologiques

On repart de la base commune (sel et inter)

```{r}
# aire des communes et de leurs parties
sel$aire <- sapply(sel$geom, st_area)
inter$aire <- sapply(inter$geom, st_area)
inter <- inter [, c("INSEE_COM", "NOM_COM", "codgeo", "libgeo","aire")]
str(inter)
# il s'agit d'obtenir les rapports entre les aires par ville
pct <- function (vecteur) {(vecteur / sum(vecteur)) * 100}
# Pour pouvoir traiter chaque ville, on éclate en liste
linter <- split(inter, inter$INSEE_COM)
names(linter)
linter [[1]]
nb <- length(linter)
# l'aire est sur chaque 5e col de chacune des 46 listes
# On extrait pour toutes les listes uniquement la 5e colonne
laire <- list()
for (i in 1:nb) { 
  laire [[i]] <- linter [[i]][,5, drop = TRUE]
  names (laire) [[i]] <- linter [[i]][1,1, drop = TRUE] 
}
# on repère les communes dont les parties sont minimes par rapport au total des aires

# on cherche l'aire max
laire.pct <- lapply (laire, pct)
# on voit qu'il existe tjrs une aire principale occupant + de 90 % de la surface.
laire.pct.max <- lapply(laire.pct, max)
comOK <- laire.pct.max [laire.pct.max >= 90]
# 3 hypothèses
anomalies90 <- laire.pct.max [laire.pct.max < 90]
anomalies80 <- laire.pct.max [laire.pct.max < 80]
anomalies70 <- laire.pct.max [laire.pct.max < 70]
# 71, 28 et 16 anomalies : on produit les cartos pour chacun  des cas
# afin de vérifier rapidement quelle hypothèse est la meilleure
for (j in c(70, 80, 90)) {
  anomalies <- laire.pct.max [laire.pct.max < j]
  nom.anomalies <- names(anomalies)
  plot(commune$geom [commune$INSEE_COM %in% nom.anomalies, ])
  # cartographies
  nb <- length(nom.anomalies)
  i <- 1
  for (i in 1:nb) {
    g <- inter$geom [inter$INSEE_COM == nom.anomalies [i]]
    sizes <-
      getFigDim(
        x = g,
        width = 300,
        mar = c(0, 0, 1.2, 0),
        res = 96
      )
    png(
      paste0("../img/anomalies_", j, "_", i, ".png"),
      width = 300,
      height = sizes [2],
      res = 96
    )
    par(mar = c(0, 0, 1.2, 0))
    plot(g, bg = "antiquewhite1")
    segSel <-
      st_intersection(segment, g)
    noms <- unique(segSel$libgeo)
    segmentSel <- segment [segment$libgeo %in% noms, ]
    typoLayer(segmentSel, var = "libgeo", add = TRUE)
    plot(
      inter$geom [inter$INSEE_COM == nom.anomalies [i]],
      lwd = 2,
      border = "red",
      add = TRUE,
      col = NA
    )
    layoutLayer(paste0(j, "_Commune de ", inter$NOM_COM [inter$INSEE_COM == nom.anomalies [i]],  " et segments"))
    dev.off()
  }
}
```


Borne à 80 semble aller mieux.
Pour toutes les diff90 80 on prend le centroid
pour les parties 80, centroid de chaque partie

```{r}
comOK <- laire.pct.max [laire.pct.max >= 80]
#11727
anomalies80 <- laire.pct.max [laire.pct.max < 80]
names(anomalies80)
# pour toutes ces communes, on prend le fichier des parties et on attribue le
# segment du centroid des parties
# pour mémoire fichier des parties
parties <- st_intersection(commune [commune$INSEE_COM %in% names(anomalies80),],segment)
# 70 parties pour 28 communnes
# on élimine les petites parties
parties$aire <- (sapply(parties$geom, st_area)/10000)
plot(parties$aire)
lparties <- split(parties,  parties$INSEE_COM)

nb <- length(lparties)
laire <- list()
for (i in 1:nb) { 
  laire [[i]] <- lparties [[i]][,5, drop = TRUE]
  names (laire) [[i]] <- lparties [[i]][1,1, drop = TRUE] 
}

laire.pct <- lapply(laire, pct)
aire.pct <- unlist(laire.pct)
plot(sort(aire.pct))
aire20 <- aire.pct [aire.pct < 20]
noms20 <-  names(aire20)
plot(comSeg)
```



## Table finale

Idée : sauf pour les 71 anomalies, reprendre les centroides

(C'est quand même beaucoup plus simple.)

```{r}
nom.anomalies
centr <- st_centroid(commune)
res <- st_intersection(centr, segment)
# 31565 communes sur 34868.pourquoi une différence de 3 303 ? Il s'agit sans doute des centroids sur espace sans segment.
# Mais il devrait y en avoir moins (71, cf calculs ci-dessous)
# on supprime les anomales
head(res)
res <- res [!(res$INSEE_COM %in% nom.anomalies), ]
res <- res [, c("INSEE_COM", "NOM_COM", "codgeo", "libgeo"), drop= TRUE]
# 31494 communes sur 31565, les 71 anomalies
nb <- 31565 - nrow(res)
length(nom.anomalies)- nb

```

reste les 71 communes... analyse des cartographies


Analyse des 71 cas

Il reste beaucoup de cas où les aires débordent sans signification !
Trouver la bonne borne au dessus de 90 %







```{r}
borne70 <- laire.pct.max [laire.pct.max < 70]

```

