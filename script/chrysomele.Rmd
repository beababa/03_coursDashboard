---
title: "Chrysomele"
author: "B. Maranget"
date: "25/01/2021"
output: 
  html_document: 
    number_sections: yes
    toc: yes
    toc_float: true
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache = TRUE)
# Passer la valeur suivante à TRUE pour reproduire les extractions.
knitr::opts_chunk$set(eval = FALSE)
knitr::opts_chunk$set(warning = FALSE)
```

# Cadre

## Objet

Paramètres à estimer à partir fichiers rpg sur plusieurs années

- taille moyenne parcelles
- SAU moyenne
- surface moyenne mais
- idem mais en monoculture
- idem mais 1e fois

difficulté : identifiant différent

## Librairies et répertoire

```{r}
library(sf)
# Linking to GEOS 3.8.0, GDAL 3.0.4, PROJ 6.3.1
library(lwgeom) # pour la validation de la géométrie
library(cartography)
```

## Données

### Générales

```{r}
# communes sans la corse
commune <- st_read("../dataE/00_ADMIN/ign.gpkg", "commune", quiet = TRUE,stringsAsFactors = F)
dpt <- st_read("../dataE/00_ADMIN/ign.gpkg", "dpt", quiet = TRUE, stringsAsFactors = F)
canton2015 <- st_read("../dataE/00_ADMIN/canton2015/CANTON.SHP")
fond <- st_read("../dataE/00_ADMIN/nuts.gpkg", "pays", quiet = TRUE, stringsAsFactors =F)
# rpg dezipage
chemin <-"../dataE/01_CULTURES/rpg/"
noms <- list.files(chemin)
for (i in 1:length(noms)){
  unzip(zipfile =  paste0(chemin,noms[i]), exdir = chemin)
}
# assemblage
noms <- list.files(chemin, pattern = ".shp")
data <- NULL
i <- 1
for (i in 1:length(noms)){
  tmp <- st_read(paste0(chemin, noms [i]))
  tmp$an <- substring(noms [i],9,12)
  data <- rbind(data,tmp)
}
# Enregistrement en format .gpkg 972 363
rpg <- data [,c("Code_cultu", "an"), drop = FALSE]
st_write(rpg, "../dataS/chrysomele.gpkg", "rpg", row.names = FALSE,quiet = TRUE, delete_layer = TRUE)
```



### Zone test

```{r}
test2015 <- rpg2015 [rpg2015$geometry [1],]
bb <- st_as_sfc(st_bbox(test2015))
test2015 <- st_intersection( st_make_valid(rpg2015), bb)
test2016 <- st_intersection( st_make_valid(rpg2015), bb)
test2017 <- st_intersection( st_make_valid(rpg2017), bb)
test2018 <- st_intersection( st_make_valid(rpg2018), bb)
ltest <- list(test2015, test2016, test2017, test2018)
names(ltest) <- c("test2015", "test2016", "test2017", "test2018")
# observation différence
plot(test2015$geometry)
plot(test2016$geometry, col = "red", add = TRUE)
plot(test2017$geometry, col = "blue", add = TRUE)
plot(test2018$geometry, col = "green", add = TRUE)
test_2015_2016 <- st_equals(test2015, test2016, sparse = T)
table(sapply(test_2015_2016, length))
# sur 21 geometries, 9 sont différentes...
rpg2015_2016  <- st_equals(st_make_valid(rpg2015), st_make_valid(rpg2016), sparse = T)
table(sapply(rpg2015_2016, length))
# meme proportion
```



### Zones d'étude

```{r}
alsace <- read.csv2("../dataE/00_ADMIN/alsace.csv")
names(alsace) <- c("zone", "PR", "nom", "CODE_CANTO")
canton2012 <- st_read("../dataE/00_ADMIN/canton2012/CANTON.SHP", quiet = TRUE, stringsAsFactors = TRUE)
str(alsace)
str(canton2012)
cantonS <- canton2012 [ canton2012$NOM_REG == "ALSACE",]
alsace.sf <- merge (cantonS, alsace, by = "CODE_CANTO")
alsace.sf <- alsace.sf [, c("CODE_CANTO", "ID_GEOFLA","zone", "PR", "nom" ),]
st_write(alsace.sf, "../dataS/chrysomele.gpkg", "cantonAlsace", quiet = TRUE, delete_layer = TRUE)
plot(alsace.sf$geometry)
```

## Méthodes

### Opérateurs spatiaux

![](../img/opspatiaux.png)

### Suppression des unités m2

```{r}
library("units")
drop_units(rpg)
```

## Exploration rpg 

### Nombre d'occurences

```{r}
par(mar = c(4,4,4,4))
tab <- addmargins(table(rpg$Code_cultu, rpg$an))
knitr::kable(tab)
```

### Taille moyenne des parcelles agricole

```{r, eval = TRUE}
rpg <- st_read("../dataS/chrysomele.gpkg", "rpg", quiet = TRUE, stringsAsFactors = FALSE)
calcul <- function(data) {
  aire <- sum(st_area(data))/10000
  moyenne <-(sum(st_area(data)) / nrow(data))/10000
  res <- c(aire, moyenne)
  } 
# liste
lrpg <- split(rpg, rpg$an)
names(lrpg) <- c("rpg2015", "rpg2016", "rpg2017", "rpg2018")
ttsCultures <- sapply(lrpg,calcul)
# uniquement mais 275 234 obs
rpgMais <- rpg [rpg$Code_cultu %in% c("MID", "MIE", "MIS"), ]
st_write(rpgMais, "../dataS/chrysomele.gpkg", "rpgMais", quiet = TRUE, delete_layer = TRUE)
# liste
lrpgMais <- split(rpgMais, rpgMais$an)
names(lrpgMais) <- c("rpg2015", "rpg2016", "rpg2017", "rpg2018")
mais <- sapply(lrpgMais, calcul)
# assemblage et moyenne
total <- rbind(ttsCultures, mais)
moyenne <- apply(total,1, mean)
total <- cbind(total, moyenne)
noms <- c("tts total", "tts moy", "tts mais", "moy mais")
knitr::kable(total, digits = 2)
```


# Méthodes possibles

## Centroides

Pour éviter les problèmes topologiques liés aux contours de parcelles. On utilise les centroides.

```{r}
data <- c("test2015", "test2016", "test2017", "test2018")
ldata <- list(test2015,test2016,test2017,test2018)
names(ldata) <- c("année1", "année2", "année3", "année4")
lcentr <- lapply(ldata, st_centroid)
str(lcentr)
aspect <- c(0,10,20,3)
col <- c("red", "green", "blue", "black")
plot(test2015$geometry)
for (i in 1:4) {
  plot(lcentr [[i]][10], pch = aspect [i], col = col [i], add = TRUE)
}
```

Assez peu de superposition des centroïdes. La solution est écartée.

## Grille

Comme les géométries ne semblent pas se superposer, on utilise une grille dont chaque carreau fait 1 hac.

https://rcarto.github.io/carto_avec_r/chapitre3.html#les-grilles-r%C3%A9guli%C3%A8res


![](../img/carroyage.png)

```{r}
grid <- st_make_grid(bb, cellsize = 100)
plot(test2015$geometry)
plot(grid, add = TRUE)
```


```{r}
inter <- function(data) { st_intersection(data, grid)}
linter <- lapply(ldata, inter)
sapply(linter, nrow)
```

La différence du nombre des carreaux montrent que les géométries sont différentes.

L'objet de référence est désormais une liste.

Cela permet d'appliquer rapidement les mêmes traitements avec *lapply* et des fonctions spécifiques  (cf fonction *inter* ci-dessus, permet d'intersecter les géométries avec la grille.

Inconvénient : manipulation des objets plus lourde ([[i]])

Avantage : éviter les boucles

Exemple de fonction : calculer le % aire pour chaque carré de la grille
Ceci permettra de donner une valeur continue à chaque carreau. Par exemple, si on veut cartographier
le % de maïs sur chacune des 4 années et comparer les cartes.

TO DO

```{r}
pct <- function(aire) { (aire / 10000) * 100}
laire <- lapply(linter, st_area)
lcoeff <- lapply(laire, pct)
```


Cependant dans le cas présent, la grille sert à rien. Puisqu'on utilise uniquement les opérateurs
spatiaux pour déterminer une aire qui servira de base au calcul.

L'équivalent serait de combiner les coeff pour obtenir une moyenne d'occupation de carreau par exemple.
Cela permettra de vérifier la justesse de nos résultats par manipulations spatiales.

TO DO

# Méthode utilisée : Manipulations spatiales


## Allègement des données, uniquement le maïs


L'idée est de retenir uniquement les carreaux maïs ("BTH" pour les besoins du test), cela allège considérablement la base !


```{r}
# filtrage des carreaux
sel <- function (data) {data [data [,4, drop = TRUE] == "BTH",]}
ldataBTH <- lapply (linter, sel)
couleur <- c("red","blue", "green", "black")
par(mar = c(0,0,1.2,0), mfrow = c(2,2))
i <- 1
for (i in 1:4) {
  plot(ldataBTH [[i]][10], border = couleur [i])
  layoutLayer(title = names(ldataBTH [i]))
}
```

ldataBTH est désormais notre objet de référence. 

## Uniquement le maïs sur les 4 ans

Sur 4 ans, les carreaux maïs et rien d'autre.

```{r}
res1 <- st_intersection(ldataBTH$année1, ldataBTH$année2)
res2 <- st_intersection(res1, ldataBTH$année3)
res3 <- st_intersection (res2, ldataBTH$année4)
aireMais <- round(sum(st_area(res3))/10000,2)
plot(res3$geometry)
plot(test2015$geometry)
plot(res3, add = TRUE)
layoutLayer(paste0("aire blé cultivé uniquement en 2015 : ",aireMais, " ha"))
# on calcule l'aire de res3 uniquement
```

TO DO fonction récursive

TO DO pourquoi des points sur le plot ?

## Uniquement mais en 2015

Union des 3 années et différence avec 2015

sans quadrillage (problème de CRS avec le quadrillage)

```{r}
ltestBTH <- lapply (ldata, sel)
# assembler les polygones des différentes couches
Y <- st_union(st_union(ltestBTH$test2016), st_union(ltestBTH$test2017), st_union(ltestBTH$test2018))
X <- st_union(ltestBTH$test2015)
# graphique
par(mfrow = c(1,2))
plot(X)
plot(Y, col = "blue")
# parcelle où mais cultivé en 2015
res1 <- st_difference(X, Y)
plot(res1)
(round(st_area(res1),0))
```

Remarque : il faut appliquer une union des polygones avant de faire la différence sinon la différence
se fera sur chaque polygone
Du coup, on crée applique st_union une bonne fois pour toute !

```{r}
lunion <- lapply(ltestBTH, st_union)
```


## Uniquement mais en 2016, 2017, 2018

On crée une fonction ayant pour paramètre l'année de la demande.

```{r, eval=TRUE}
anneeUnique <- function(lunion, num) {
  X <- lunion [[num]]
  lreste <- lunion
  lreste [[num]] <- NULL
  Y <- st_union(lreste [[1]], lreste [[2]], lreste [[3]])
  res <- st_difference(X,Y)
  # graphique
  # par(mfrow = c(1, 3))
  # plot(X, main = num)
  # plot(Y, col = "blue", main = "autres")
  # plot(res, main = "difference")
  round(st_area(res)/10000,0)
}
```


```{r}
lnum <- c(1,2,3,4)
sapply(lunion, anneeUnique)
```

TODO pb géometries pas complètes

## Deux ans sur les quatre ans

Intersection des années et différence entre les deux géométries créées
Directement en fonction

```{r, eval=TRUE}
deuxAnsOLD <- function (num1,num2, lunion) {
  X <- st_union(lunion [[num1]], lunion [[num2]])
  lreste <-lunion [c(-num1,-num2)]
  Y <- st_union (lreste [[1]], lreste [[2]])
  # Toutes les géométries de X qui ne sont pas dans Y
  res <- st_difference(X,Y )
  # couteux
  # graphique
  # par(mfrow = c(2, 2))
  # plot(X, main = paste(num1, num2))
  # plot(Y, col = "blue", main = "autres")
  # plot(res, main = "difference")
  # Elimination des petits petits polygones (500 m2)
  # TO DO valider cette limite
  
  #res2 <- st_cast(res, "MULTILINESTRING")
  res3 <- st_cast(res, "MULTIPOLYGON")
  res4 <- sapply(st_as_sf(res3), st_area)
  indice <- which(round(res4,0) > 500)
  #plot(res2 [indice], main = "retenu")
  res5 <- round(st_area (res3 [indice]),0)
  return(res5)
  }

deuxAns <- function (num1,num2, lunion) {
  X <- st_union(lunion [[num1]], lunion [[num2]])
  lreste <-lunion [c(-num1,-num2)]
  Y <- st_union (lreste [[1]], lreste [[2]])
  # Toutes les géométries de X qui ne sont pas dans Y
  res <- 
    st_cast(st_difference(X,Y ), "MULTIPOLYGON")
    
  # couteux
  # graphique
  # par(mfrow = c(2, 2))
  # plot(X, main = paste(num1, num2))
  # plot(Y, col = "blue", main = "autres")
  # plot(res, main = "difference")
  # Elimination des petits petits polygones (500 m2)
  # TO DO valider cette limite
  
  #res2 <- st_cast(res, "MULTILINESTRING")
  res2 <- sapply(st_as_sf(res), st_area)
  indice <- which(round(res2,0) > 500)
  #plot(res2 [indice], main = "retenu")
  res3 <- round(res2 [indice],0)
  return(res3)
  }

```


On a donc testé sur un très petit échantillon deux fonctions : annéeUnique et deuxAns.
Il s'agit maintenant de l'appliquer à notre jeu de données unique.


# Zone d'étude Alsace

## Mise en forme des données : agrégation aux 4 zones de l'Alsace

Les données du RPG, même pour une seule région, sont très lourdes et le R de base les manipule mal, 
2 solutions explorées :
- éclater les fichiers selon des zones géographiques et puis les années permettra de faciliter les traitements.
- dissoudre les petites parcelles (cf taille moyenne très basse) sur chacune des zones et des années, il faut vérifier que cela allège

Pour le faire, tout unir, et éclater.

TODO exploration diplyr plus efficace que le R de base ?

TODO utiliser base postgis ?

### Intersection zones et rpb

```{r}
alsace <- st_read("../dataS/chrysomele.gpkg", "cantonAlsace", quiet = TRUE, stringsAsFactors = FALSE)
rpg <- st_read("../dataS/chrysomele.gpkg", "rpgMais", quiet = TRUE, stringsAsFactors = FALSE)
# 275 324 obs
# agrégation par zones
aggAlsace <- aggregate(alsace [,c("zone"), drop = FALSE], by = list (alsace$zone), length)
names(aggAlsace)[1:2] <- c("groupe", "nb")
png("../img/alsace.png")
par(mar=c(0,0,1.2,0))
ghostLayer(aggAlsace, bg = "lightblue1")
plot(fond, col = "antiquewhite3", border = NA, add = TRUE)
plot(dpt$geom, add = TRUE, col = "antiquewhite2", border = NA)
plot(aggAlsace$geometry, col = "antiquewhite1", border = "grey", add= TRUE)
labelLayer(aggAlsace, txt = "groupe", halo = 2 )
layoutLayer(title = "Zones d'étude Alsace")
dev.off()
# intersection très couteuse. géométrie du rpg nécessite de forcer la validité
inter <- st_intersection(st_make_valid(rpg), aggAlsace)
# On travaillera à partir de ce fichier désormais.
st_write(inter, "../dataS/chrysomele.gpkg", "inter", quiet = TRUE, delete_layer = TRUE)
```

![](../img/alsace.png)

TODO Attention zone Strasbourg absente ?

### Organiser la donnée par zone et année en fusionnant les parcelles adjacentes

Trois fonctions correspondant à trois étapes de traitement
Sur les données :
- on éclate les données par zone puis par an
Sur la géométrie : 
- on la rend valide en supprimant les types multiples, afin d'obtenir uniquement des polygones
- puis on efface les frontières entre parcelles
  - union de tous les polygones
  - nouvel éclatement

TODO nb de polygones au départ / à l'arrivée


```{r}
inter <- st_read("../dataS/chrysomele.")
lzone <- split(inter, inter$groupe)
# Nettoyer les géométries, c'est supprimer les geometrycollection
nettoyerGeom <- function (df) {
  df <-df [st_geometry_type(df) != "GEOMETRYCOLLECTION",]
  dfvalid <- st_make_valid(df)
  dfpoly <- st_cast(dfvalid, "POLYGON")
}
# Fusionner les parcelles adjacentes : union de tous les polygones, puis éclatement
polygoner <- function(df) {
  dfunion <- st_union(df)
  dfpoly <- st_cast(dfunion, "POLYGON")
}
# Eclater les zones et les années, car on va travailler sur la géométrie.
eclater <- function (num) {
 df <- lzone[[num]]
 ldf <- split (df, df$an)
}
# boucle sur les zones
i <- 1
noms <- c("lzone1", "lzone2", "lzone3","lzone4")
for (i in 1:4){
  leclate <- eclater (i)
  # lapply  sur les années
    lpropre <- lapply(leclate, nettoyerGeom)
    lpoly <- lapply(lpropre,polygoner)
    assign(noms [i], lpoly)
  }
# 149 / 43.2 / 64.1 et 3 M°
# enregistrement en fichiers pour qgis`
enregistrer <- function(df,num) {
  #  on récupère le nom de la zone
  zone <- substring(deparse(substitute(lzone4$`2015`)),1,6)
  annee <- substring(deparse(substitute(lzone4$`2015`)),9,12)
  st_write(df, dsn = "../dataS/chrysomelexport.gpkg", layer = paste0(zone,"_", annee), quiet = TRUE, delete_layer = TRUE)
}
```

### Etude de la distribution de l'aire

```{r}
summary(inter$aire)
# on supprime toutes les aires < 0.5
inter$aire <- round(drop_units(st_area(inter$geom)/10000),0)
inter <- inter [inter$aire > 0.5,]
# 207 334 obs
# on ne peut pas faire un st_is_valid. trop long
# sauvegarde pour éviter de refaire les manip trop coûteuse
st_write(inter, "../dataS/chrysomele.gpkg", "inter", quiet = TRUE, delete_layer = TRUE)
```

```{r, eval=TRUE}
inter <- st_read("../dataS/chrysomele.gpkg", "inter", quiet = TRUE, stringsAsFactors = FALSE)
# 274 083 obs, tous en multipolygone
# verif
summary(inter)
par(mfrow = c(1,2))
barplot(sort(inter$aire))
abline (h = mean(inter$aire))
# Un minimum à 500 pour 2015 et 2018, mais pour 2016 2017 on le monte à 10 000 (1 ha)
interSel <- inter [inter$aire > 1,]
barplot(sort(interSel$aire))
abline (h = mean(interSel$aire))
# 144 034 obs
```

Une distribution très bipolaire... pb

## Utilisation des fonctions anneeUnique et deuxAns

```{r}
#  Pour pouvoir appliquer la fonction, on fait l'union à nouveau
# parcours de la zone
objet <- c(lzone1, lzone2, lzone3, lzone4)
j <- 4
lSel <- NULL
for (j in 1:4) {
  # parcours de la zone
  lSel <- objet [j]
  # parcours de l'année
  tot <- NULL
  i <- 1
  for (i in 1:4) {
    selUnion <- st_union (lSel [[i]])
    tot <- c(tot, selUnion)
  }
 str(tot)
  
    for (i in 1:4){
    res <- c(res, anneeUnique(lunion,i))
  }
}



```

### Nouvelle méthode : R + QGIS

En fait, on a besoin d'enregistrer le fichier de l'année et celui des 3 autres. On fera la différence sous Qgis.
En effet, la différence ne nécessite pas de st_union et le traitement est moins long que sous R.

```{r}
 df <- zone2
 num <- 1
enregistrerAnneeUnique <- function(df, num) {
  zone <- deparse(substitute(df))
  print(zone)
  nomAn <- c("2015","2016","2017", "2018")
  X <- df [df$an == nomAn [num], ]
  Y <- df [df$an != nomAn [num],]
  # L'union peut se faire sous R quand même non ?
   Xunion <- st_union(X)
   Yunion <- st_union(Y)
  res <- st_difference(Xunion,Yunion )
  # obligation d'enregistrer dans des gpkg sinon qgis ne les voit pas
  nomgpkg <- paste0("../dataS/chrysomelexport",zone,".gpkg")
  st_write(X, dsn = nomgpkg, layer = paste0(zone,"_", nomAn[num]), quiet = TRUE, delete_layer = TRUE)
  st_write(Y, dsn = nomgpkg, layer = paste0(zone,"_autres_", nomAn[num]), quiet = TRUE, delete_layer = TRUE)
  return(res)
}
```


Essai de nettoyage de la donnée
```{r}
anomalie <- st_is_valid(zone1, reason = TRUE)
table(anomalie, useNA = "always")
sf_extSoftVersion()["lwgeom"]
# inutile de faire st_make_valid, lwgeom n'existe pas
```


Enregistrement des données pour Qgis

Pour chaque année, deux couches, celle de l'année X et celle de toutes les années Y.

```{r}
#boucle pour les zones
for (i in 1:4) {
  zone <- lzone [[i]]
  # on met la barre à 10 000 (1 ha)
  zone <- zone [zone$aire > 10000, ]
  # boucle pour les années
  for (j in 1:4) {
    enregistrerAnneeUnique(zone, j)
  }
}
```


On récupère la couche de différence

```{r, eval = TRUE}
couche <- c("2015", "2016", "2017", "2018")
total <- NULL
i <- 1
for (i in 1:4) {
  diff <-
    st_read("../dataS/chrysomelediff.gpkg",
            layer = couche [i],
            quiet = TRUE)
    total <- rbind(total,sum(st_area(diff)))
}
rownames(total) <- couche
colnames(total) <- "zone1"
total <- round(total/10000,0)
# total des différences années et autres années (aires en ha)
total
```

TODO 2016 et 17 ne passent pas sous Qgis, sans doute pour un pb de polygone trop petit provoquant une 
erreur de topologie. 

![](../img/qgisdiffpb.png)


....et l'explication


![](../img/cause.png)

reférence : https://github.com/Turfjs/turf/issues/1575

Donc supprimer les polygones trop petits, faire sous Qgis
... Et vérifier que cela ne passe pas sous R (voir st_make_valid, st_valid et st_geometry_type)

TODO macro R sous Qgis pour éviter les AR voire python

Nettoyage couche chrysomele

```{r}
library(rgdal)
ogrListLayers("../dataS/chrysomele.gpkg")
```

